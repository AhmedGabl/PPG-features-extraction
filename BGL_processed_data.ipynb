{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb688eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 39.7807229856575\n",
      "Test RMSE: 38.760477007271994\n",
      "Train MAE: 24.039074319707648\n",
      "Test MAE: 23.435092948946956\n",
      "Train R^2: 0.1540444646194714\n",
      "Test R^2: 0.1445748401145075\n",
      "Train Explained Variance Score: 0.1540444646194714\n",
      "Test Explained Variance Score: 0.1452113395640956\n"
     ]
    }
   ],
   "source": [
    "#Ridge regression model with default parameters\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Data loading\n",
    "data = pd.read_excel('BGL_Data/Glu.xlsx')\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Select relevant columns for analysis and perform preprocessing\n",
    "selected_columns = ['Age', 'Blood Glucose Level(BGL)', 'Diastolic Blood Pressure', 'Systolic Blood Pressure',\n",
    "                    'Heart Rate', 'SPO2']\n",
    "preprocessed_data = data[selected_columns]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = preprocessed_data.drop(['Blood Glucose Level(BGL)'], axis=1)\n",
    "y = preprocessed_data['Blood Glucose Level(BGL)']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modeling\n",
    "model = Ridge(alpha=1.0, solver='auto', random_state=42)  # Ridge regression model with default parameters\n",
    "\n",
    "# Model fitting\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Model evaluation\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "train_ev = explained_variance_score(y_train, y_train_pred)\n",
    "test_ev = explained_variance_score(y_test, y_test_pred)\n",
    "\n",
    "print('Train RMSE:', train_rmse)\n",
    "print('Test RMSE:', test_rmse)\n",
    "print('Train MAE:', train_mae)\n",
    "print('Test MAE:', test_mae)\n",
    "print('Train R^2:', train_r2)\n",
    "print('Test R^2:', test_r2)\n",
    "print('Train Explained Variance Score:', train_ev)\n",
    "print('Test Explained Variance Score:', test_ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae73106f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 16.23180936136771\n",
      "Test RMSE: 16.22110453459565\n",
      "Train MAE: 13.162859878501017\n",
      "Test MAE: 13.123505990844235\n",
      "Train R^2: 0.4114533441231196\n",
      "Test R^2: 0.4170280101862477\n",
      "Train Explained Variance Score: 0.41145334412311974\n",
      "Test Explained Variance Score: 0.41703462369842326\n"
     ]
    }
   ],
   "source": [
    "#linear regressoin with the preprocessed data\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Data loading\n",
    "data = pd.read_excel('BGL_Data/pr_PG2.xlsx')  #PG2.xlsx\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Select relevant columns for analysis\n",
    "selected_columns = [ 'Age', 'Blood Glucose Level(BGL)', 'Heart Rate', 'Diastolic Blood Pressure', 'Systolic Blood Pressure', 'SPO2']\n",
    "preprocessed_data = data[selected_columns].copy()\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X = preprocessed_data.drop(['Blood Glucose Level(BGL)'], axis=1)\n",
    "y = preprocessed_data['Blood Glucose Level(BGL)']\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "# Model evaluation\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "train_ev = explained_variance_score(y_train, y_train_pred)\n",
    "test_ev = explained_variance_score(y_test, y_test_pred)\n",
    "\n",
    "print('Train RMSE:', train_rmse)\n",
    "print('Test RMSE:', test_rmse)\n",
    "print('Train MAE:', train_mae)\n",
    "print('Test MAE:', test_mae)\n",
    "print('Train R^2:', train_r2)\n",
    "print('Test R^2:', test_r2)\n",
    "print('Train Explained Variance Score:', train_ev)\n",
    "print('Test Explained Variance Score:', test_ev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b2d5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "175/175 [==============================] - 7s 31ms/step - loss: 697.4164 - val_loss: 223.8250\n",
      "Epoch 2/3\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 271.1824 - val_loss: 150.1489\n",
      "Epoch 3/3\n",
      "175/175 [==============================] - 5s 29ms/step - loss: 256.6875 - val_loss: 161.2410\n",
      "350/350 [==============================] - 2s 4ms/step\n",
      "62/62 [==============================] - 0s 5ms/step\n",
      "Train RMSE: 15.921038372463803\n",
      "Test RMSE: 15.967575255710123\n",
      "Train MAE: 12.492037504588962\n",
      "Test MAE: 12.579149153457225\n",
      "Train R^2: 0.43377399955477425\n",
      "Test R^2: 0.4351088304184634\n",
      "Train Explained Variance Score: 0.49618321493199835\n",
      "Test Explained Variance Score: 0.4918485537399765\n"
     ]
    }
   ],
   "source": [
    "#neural network with the preprocessed data\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Data loading\n",
    "data = pd.read_excel('BGL_Data/pr_PG2.xlsx')  #PG2.xlsx\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Select relevant columns for analysis\n",
    "selected_columns = [ 'Age', 'Blood Glucose Level(BGL)', 'Heart Rate', 'Diastolic Blood Pressure', 'Systolic Blood Pressure', 'SPO2']\n",
    "preprocessed_data = data[selected_columns].copy()\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X = preprocessed_data.drop(['Blood Glucose Level(BGL)'], axis=1)\n",
    "y = preprocessed_data['Blood Glucose Level(BGL)']\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Modeling\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(1000, activation=tf.nn.relu, input_shape=(X.shape[1],)),\n",
    "    tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(500, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1)  # Single output unit for regression\n",
    "])\n",
    "\n",
    "# Model parameters\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Model fitting\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=3, validation_split=0.0002)\n",
    "\n",
    "# Model evaluation\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "train_ev = explained_variance_score(y_train, y_train_pred)\n",
    "test_ev = explained_variance_score(y_test, y_test_pred)\n",
    "\n",
    "print('Train RMSE:', train_rmse)\n",
    "print('Test RMSE:', test_rmse)\n",
    "print('Train MAE:', train_mae)\n",
    "print('Test MAE:', test_mae)\n",
    "print('Train R^2:', train_r2)\n",
    "print('Test R^2:', test_r2)\n",
    "print('Train Explained Variance Score:', train_ev)\n",
    "print('Test Explained Variance Score:', test_ev)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df396af8",
   "metadata": {},
   "source": [
    "Now after training chose best performence to move on with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1836a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# Specify the file path to save the model\n",
    "file_path = os.path.join(current_path, 'model_1.h5')\n",
    "\n",
    "# Save the model\n",
    "model.save(file_path)\n",
    "\n",
    "# Print the saved file path\n",
    "print('Model saved at:', file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6e028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('model_1.h5')\n",
    "\n",
    "# Define the input for prediction\n",
    "new_input = np.array([[60, 78, 66, 105, 94]])  # Example input data, adjust as needed\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_input)\n",
    "\n",
    "# Print the predictions\n",
    "for prediction in predictions:\n",
    "    print(prediction[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe0fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model parameters\n",
    "model.save_weights('M1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c8942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Define the input data for prediction\n",
    "new_input = np.array([[30, 80, 70, 120, 95]])  # Example input data, adjust as needed\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(1000, activation=tf.nn.relu, input_shape=(new_input.shape[1],)),\n",
    "    tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(500, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1)  # Single output unit for regression\n",
    "])\n",
    "\n",
    "# Load the saved model parameters\n",
    "model.load_weights('M1.h5')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_input)\n",
    "\n",
    "# Print the predictions\n",
    "for prediction in predictions:\n",
    "    print(prediction[0])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "208d02b3",
   "metadata": {},
   "source": [
    "\n",
    "# Define the input for prediction\n",
    "new_input = np.array([[23, 60, 80, 120, 95 ]])  # Example input data, adjust as needed\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_input)\n",
    "\n",
    "# Print the predictions\n",
    "for prediction in predictions:\n",
    "    print(prediction[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
